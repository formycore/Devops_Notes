Devops pro manual scheduling

1) create a pod on the control-plane 
- kubectl label nodes <node-name> key=value
- kubectl label nodes control-plane colour=blue
- kubeclt run pod --image=nginx --restart=Always --dry-run=client -o yaml > pod1.yml
- edit the pod1.yml under spec nodeName: control-plane
- kubectl apply -f pod1.yml

2) resechdule the pod on node01
- if we try to change the value 
3) create two pods with colour=blue (for label -l )

setting the label to nodes
- kubectl label nodes <node-name> key=value
- kubectl label nodes controlplane colour=blue
- kubectl run pod1 --image=nginx -l colour=blue restart=Always -o yaml > pod1.yml
- edit the pod1.yml under spec nodeName: <node-name>
- 


kubectl run pod --image=nginx --restart=Never --dry-run=client -o yaml > pod1.yml
controlplane $ cat pod1.yml    
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: pod
  name: pod
spec:
  containers:
  - image: nginx
    name: pod
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Never
status: {}
controlplane $ vim pod1.yml 
controlplane $ kubectl apply -f pod1.yml 
pod/pod created
controlplane $ kubectl get pods -o wide
NAME   READY   STATUS              RESTARTS   AGE   IP       NODE           NOMINATED NODE   READINESS GATES
pod    0/1     ContainerCreating   0          7s    <none>   controlplane   <none>           <none>
controlplane $ kubectl get nodes
NAME           STATUS   ROLES           AGE    VERSION
controlplane   Ready    control-plane   4d5h   v1.31.0
node01         Ready    <none>          4d5h   v1.31.0
controlplane $ kubectl get pods -o wide
NAME   READY   STATUS    RESTARTS   AGE    IP            NODE           NOMINATED NODE   READINESS GATES
pod    1/1     Running   0          4m8s   192.168.0.4   controlplane   <none>           <none>
controlplane $ vim dep.yml
controlplane $ kubectl apply -f dep.yml 
deployment.apps/deploy created
controlplane $ kubectl get pods -o wide
NAME                      READY   STATUS    RESTARTS   AGE     IP            NODE           NOMINATED NODE   READINESS GATES
deploy-84cccfcf84-7gtcj   1/1     Running   0          7s      192.168.0.6   controlplane   <none>           <none>
deploy-84cccfcf84-m5lsc   1/1     Running   0          7s      192.168.0.5   controlplane   <none>           <none>
deploy-84cccfcf84-zmtnv   1/1     Running   0          7s      192.168.0.7   controlplane   <none>           <none>
pod                       1/1     Running   0          4m37s   192.168.0.4   controlplane   <none>           <none>
controlplane $ kubectl scale --help    
Set a new size for a deployment, replica set, replication controller, or stateful set.

 Scale also allows users to specify one or more preconditions for the scale action.

 If --current-replicas or --resource-version is specified, it is validated before the scale is attempted, and it is
guaranteed that the precondition holds true when the scale is sent to the server.

Examples:
  # Scale a replica set named 'foo' to 3
  kubectl scale --replicas=3 rs/foo
  
  # Scale a resource identified by type and name specified in "foo.yaml" to 3
  kubectl scale --replicas=3 -f foo.yaml
  
  # If the deployment named mysql's current size is 2, scale mysql to 3
  kubectl scale --current-replicas=2 --replicas=3 deployment/mysql
  
  # Scale multiple replication controllers
  kubectl scale --replicas=5 rc/example1 rc/example2 rc/example3
  
  # Scale stateful set named 'web' to 3
  kubectl scale --replicas=3 statefulset/web

Options:
    --all=false:
        Select all resources in the namespace of the specified resource types

    --allow-missing-template-keys=true:
        If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to
        golang and jsonpath output formats.

    --current-replicas=-1:
        Precondition for current size. Requires that the current size of the resource match this value in order to
        scale. -1 (default) for no condition.

    --dry-run='none':
        Must be "none", "server", or "client". If client strategy, only print the object that would be sent, without
        sending it. If server strategy, submit server-side request without persisting the resource.

    -f, --filename=[]:
        Filename, directory, or URL to files identifying the resource to set a new size

    -k, --kustomize='':
        Process the kustomization directory. This flag can't be used together with -f or -R.

    -o, --output='':
        Output format. One of: (json, yaml, name, go-template, go-template-file, template, templatefile, jsonpath,
        jsonpath-as-json, jsonpath-file).

    -R, --recursive=false:
        Process the directory used in -f, --filename recursively. Useful when you want to manage related manifests
        organized within the same directory.

    --replicas=0:
        The new desired number of replicas. Required.

    --resource-version='':
        Precondition for resource version. Requires that the current resource version match this value in order to
        scale.

    -l, --selector='':
        Selector (label query) to filter on, supports '=', '==', and '!='.(e.g. -l key1=value1,key2=value2). Matching
        objects must satisfy all of the specified label constraints.

    --show-managed-fields=false:
        If true, keep the managedFields when printing objects in JSON or YAML format.

    --template='':
        Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format
        is golang templates [http://golang.org/pkg/text/template/#pkg-overview].

    --timeout=0s:
        The length of time to wait before giving up on a scale operation, zero means don't wait. Any other values
        should contain a corresponding time unit (e.g. 1s, 2m, 3h).

Usage:
  kubectl scale [--resource-version=version] [--current-replicas=count] --replicas=COUNT (-f FILENAME | TYPE NAME)
[options]

Use "kubectl options" for a list of global command-line options (applies to all commands).
controlplane $ kubectl scale --current-replica=3 --replicas=10 ^C  
controlplane $ kubectl get deploy
NAME     READY   UP-TO-DATE   AVAILABLE   AGE
deploy   3/3     3            3           2m37s
controlplane $ kubectl scale --current-replicas=3 --replicas=10 deployment/deploy
deployment.apps/deploy scaled
controlplane $ kubectl get pods -o wide
NAME                      READY   STATUS              RESTARTS   AGE     IP             NODE           NOMINATED NODE   READINESS GATES
deploy-84cccfcf84-7gtcj   1/1     Running             0          3m24s   192.168.0.6    controlplane   <none>           <none>
deploy-84cccfcf84-8cvxc   0/1     ContainerCreating   0          6s      <none>         controlplane   <none>           <none>
deploy-84cccfcf84-9mkqw   0/1     ContainerCreating   0          6s      <none>         controlplane   <none>           <none>
deploy-84cccfcf84-c928g   1/1     Running             0          6s      192.168.0.10   controlplane   <none>           <none>
deploy-84cccfcf84-cmfdd   1/1     Running             0          6s      192.168.0.11   controlplane   <none>           <none>
deploy-84cccfcf84-g2mqz   1/1     Running             0          6s      192.168.0.9    controlplane   <none>           <none>
deploy-84cccfcf84-m5lsc   1/1     Running             0          3m24s   192.168.0.5    controlplane   <none>           <none>
deploy-84cccfcf84-rsjnd   1/1     Running             0          6s      192.168.0.8    controlplane   <none>           <none>
deploy-84cccfcf84-wl8vz   1/1     Running             0          6s      192.168.0.12   controlplane   <none>           <none>
deploy-84cccfcf84-zmtnv   1/1     Running             0          3m24s   192.168.0.7    controlplane   <none>           <none>
pod                       1/1     Running             0          7m54s   192.168.0.4    controlplane   <none>           <none>
controlplane $ kubectl get pods -o wide
NAME                      READY   STATUS    RESTARTS   AGE     IP             NODE           NOMINATED NODE   READINESS GATES
deploy-84cccfcf84-7gtcj   1/1     Running   0          3m30s   192.168.0.6    controlplane   <none>           <none>
deploy-84cccfcf84-8cvxc   1/1     Running   0          12s     192.168.0.14   controlplane   <none>           <none>
deploy-84cccfcf84-9mkqw   1/1     Running   0          12s     192.168.0.13   controlplane   <none>           <none>
deploy-84cccfcf84-c928g   1/1     Running   0          12s     192.168.0.10   controlplane   <none>           <none>
deploy-84cccfcf84-cmfdd   1/1     Running   0          12s     192.168.0.11   controlplane   <none>           <none>
deploy-84cccfcf84-g2mqz   1/1     Running   0          12s     192.168.0.9    controlplane   <none>           <none>
deploy-84cccfcf84-m5lsc   1/1     Running   0          3m30s   192.168.0.5    controlplane   <none>           <none>
deploy-84cccfcf84-rsjnd   1/1     Running   0          12s     192.168.0.8    controlplane   <none>           <none>
deploy-84cccfcf84-wl8vz   1/1     Running   0          12s     192.168.0.12   controlplane   <none>           <none>
deploy-84cccfcf84-zmtnv   1/1     Running   0          3m30s   192.168.0.7    controlplane   <none>           <none>
pod                       1/1     Running   0          8m      192.168.0.4    controlplane   <none>           <none>
controlplane $ BB